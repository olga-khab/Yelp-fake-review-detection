{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emotion_and_LIWC = pd.read_csv(\"LIWC_and_emotions.csv\")\n",
    "pos = (df_emotion_and_LIWC[df_emotion_and_LIWC[\"flagged\"]==\"Y\"])\n",
    "neg= (df_emotion_and_LIWC[df_emotion_and_LIWC[\"flagged\"]==\"N\"])\n",
    "df_neg_only = neg.sample(n=len(pos))\n",
    "\n",
    "df_emotion = pd.concat([df_neg_only, pos])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16320 entries, 6263 to 16409\n",
      "Data columns (total 27 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   date          16320 non-null  object \n",
      " 1   reviewID      16320 non-null  object \n",
      " 2   reviewerID    16320 non-null  object \n",
      " 3   review        16320 non-null  object \n",
      " 4   rating        16320 non-null  int64  \n",
      " 5   flagged       16320 non-null  object \n",
      " 6   restaurantID  16320 non-null  object \n",
      " 7   WC            16320 non-null  int64  \n",
      " 8   Analytic      16320 non-null  float64\n",
      " 9   Clout         16320 non-null  float64\n",
      " 10  Authentic     16320 non-null  float64\n",
      " 11  Tone          16320 non-null  float64\n",
      " 12  WPS           16320 non-null  float64\n",
      " 13  Sixltr        16320 non-null  float64\n",
      " 14  pronoun       16320 non-null  float64\n",
      " 15  ppron         16320 non-null  float64\n",
      " 16  i             16320 non-null  float64\n",
      " 17  we            16320 non-null  float64\n",
      " 18  you           16320 non-null  float64\n",
      " 19  shehe         16320 non-null  float64\n",
      " 20  they          16320 non-null  float64\n",
      " 21  ipron         16320 non-null  float64\n",
      " 22  sadness       16320 non-null  float64\n",
      " 23  anger         16320 non-null  float64\n",
      " 24  disgust       16320 non-null  float64\n",
      " 25  joy           16320 non-null  float64\n",
      " 26  fear          16320 non-null  float64\n",
      "dtypes: float64(19), int64(2), object(6)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_emotion.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replicating LIWC PACIS paper: T-tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features:\n",
    "\n",
    "**LIWC**\n",
    "- WC\n",
    "- Analytical\n",
    "- Tone\n",
    "- Authentic\n",
    "- Clout\n",
    "\n",
    "**Other**\n",
    "- Readability (Coleman Liau index)\n",
    "- Rating extremity (the absolute difference of review star rating and existing business star rating)\n",
    "- Days (days from the reviews date to the data collection date)\n",
    "\n",
    "**To try**\n",
    "- Days (days from first review to this review)\n",
    "- Emotion extremity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_paired = df_emotion.drop(columns=[\"date\",\"reviewID\",\"reviewerID\",\"review\",\"rating\",\"restaurantID\",\"pronoun\",\"i\", \"we\", \"you\", \"shehe\", \"they\"])\n",
    "#df_paired = df_emotion.drop(columns=[\"date\",\"reviewID\",\"reviewerID\",\"review\",\"restaurantID\"])\n",
    "#df_paired\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating Readability (Coleman Liau index)\n",
    "df_emotion[\"Sentences\"] = df_emotion[\"WC\"]/df_emotion[\"WPS\"]\n",
    "\n",
    "for i,row in df_emotion.iterrows():\n",
    "    df_emotion.at[i,\"Letters\"] = sum(c.isalpha() for c in df_emotion.at[i,\"review\"])\n",
    "    #len(df_emotion.at[i,\"review\"])\n",
    "   # print(df_emotion.at[i,\"review\"])\n",
    "\n",
    "df_emotion[\"Readability\"] = (df_emotion[\"Letters\"]*100/df_emotion[\"WC\"]*0.0588)-(0.296*df_emotion[\"Sentences\"]*100/df_emotion[\"WC\"])-15.8\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Flag</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Stdev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WC</td>\n",
       "      <td>Real</td>\n",
       "      <td>146.008211</td>\n",
       "      <td>114.00</td>\n",
       "      <td>120.943490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WC</td>\n",
       "      <td>Fake</td>\n",
       "      <td>101.407475</td>\n",
       "      <td>71.00</td>\n",
       "      <td>99.644241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Analytic</td>\n",
       "      <td>Real</td>\n",
       "      <td>57.059205</td>\n",
       "      <td>58.80</td>\n",
       "      <td>23.509950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Analytic</td>\n",
       "      <td>Fake</td>\n",
       "      <td>56.974985</td>\n",
       "      <td>58.68</td>\n",
       "      <td>25.955518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tone</td>\n",
       "      <td>Real</td>\n",
       "      <td>81.754786</td>\n",
       "      <td>94.53</td>\n",
       "      <td>24.998607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tone</td>\n",
       "      <td>Fake</td>\n",
       "      <td>80.651121</td>\n",
       "      <td>97.58</td>\n",
       "      <td>28.672983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Clout</td>\n",
       "      <td>Real</td>\n",
       "      <td>47.635384</td>\n",
       "      <td>47.12</td>\n",
       "      <td>23.483563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Clout</td>\n",
       "      <td>Fake</td>\n",
       "      <td>51.715174</td>\n",
       "      <td>50.00</td>\n",
       "      <td>25.854837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Authentic</td>\n",
       "      <td>Real</td>\n",
       "      <td>48.161558</td>\n",
       "      <td>47.15</td>\n",
       "      <td>47.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Authentic</td>\n",
       "      <td>Fake</td>\n",
       "      <td>47.877473</td>\n",
       "      <td>47.07</td>\n",
       "      <td>47.070000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feature  Flag        Mean  Median       Stdev\n",
       "0         WC  Real  146.008211  114.00  120.943490\n",
       "1         WC  Fake  101.407475   71.00   99.644241\n",
       "2   Analytic  Real   57.059205   58.80   23.509950\n",
       "3   Analytic  Fake   56.974985   58.68   25.955518\n",
       "4       Tone  Real   81.754786   94.53   24.998607\n",
       "5       Tone  Fake   80.651121   97.58   28.672983\n",
       "6      Clout  Real   47.635384   47.12   23.483563\n",
       "7      Clout  Fake   51.715174   50.00   25.854837\n",
       "8  Authentic  Real   48.161558   47.15   47.150000\n",
       "9  Authentic  Fake   47.877473   47.07   47.070000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc_mean_real = np.mean(df_neg_only[\"WC\"])\n",
    "wc_median_real = np.median(df_neg_only[\"WC\"])\n",
    "wc_std_real = np.std(df_neg_only[\"WC\"])\n",
    "\n",
    "data = {'Feature':  ['WC', 'WC', \n",
    "                     'Analytic','Analytic',\n",
    "                     'Tone','Tone',\n",
    "                     'Clout','Clout',\n",
    "                     'Authentic','Authentic'],\n",
    "        'Flag': ['Real', 'Fake', 'Real', 'Fake','Real', 'Fake','Real', 'Fake','Real', 'Fake'],\n",
    "        'Mean': [np.mean(df_neg_only[\"WC\"]), np.mean(pos[\"WC\"]),\n",
    "                 np.mean(df_neg_only[\"Analytic\"]), np.mean(pos[\"Analytic\"]),\n",
    "                 np.mean(df_neg_only[\"Tone\"]), np.mean(pos[\"Tone\"]),\n",
    "                 np.mean(df_neg_only[\"Clout\"]), np.mean(pos[\"Clout\"]),\n",
    "                 np.mean(df_neg_only[\"Authentic\"]), np.mean(pos[\"Authentic\"])],\n",
    "\n",
    "        'Median': [np.median(df_neg_only[\"WC\"]), np.median(pos[\"WC\"]),\n",
    "                   np.median(df_neg_only[\"Analytic\"]), np.median(pos[\"Analytic\"]),\n",
    "                   np.median(df_neg_only[\"Tone\"]), np.median(pos[\"Tone\"]),\n",
    "                   np.median(df_neg_only[\"Clout\"]), np.median(pos[\"Clout\"]),\n",
    "                   np.median(df_neg_only[\"Authentic\"]), np.median(pos[\"Authentic\"])],\n",
    "        \n",
    "        'Stdev': [np.std(df_neg_only[\"WC\"]), np.std(pos[\"WC\"]),\n",
    "                  np.std(df_neg_only[\"Analytic\"]), np.std(pos[\"Analytic\"]),\n",
    "                  np.std(df_neg_only[\"Tone\"]), np.std(pos[\"Tone\"]),\n",
    "                  np.std(df_neg_only[\"Clout\"]), np.std(pos[\"Clout\"]),\n",
    "                  np.median(df_neg_only[\"Authentic\"]), np.median(pos[\"Authentic\"])]\n",
    "    \n",
    "        }\n",
    "\n",
    "paired_stats = pd.DataFrame(data)\n",
    "\n",
    "paired_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6127450980392157"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reg_emotion = df_emotion.drop(columns=[\"date\",\"reviewID\",\"reviewerID\",\"review\",\"rating\",\"restaurantID\",\"pronoun\",\"i\", \"we\", \"you\", \"shehe\", \"they\"])\n",
    "le_emotion = preprocessing.LabelEncoder()\n",
    "df_reg_emotion[\"flagged\"] = le_emotion.fit_transform(df_reg_emotion[\"flagged\"])\n",
    "\n",
    "X = df_reg_emotion.drop(columns=[\"flagged\"])\n",
    "Y = df_reg_emotion[\"flagged\"]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1, shuffle=True)\n",
    "clf = LogisticRegression(random_state=1, max_iter = 1000).fit(X_train, Y_train)\n",
    "clf.predict(X_test)\n",
    "clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6366421568627451"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state = 1, n_estimators=1000)\n",
    "#X = feature_selection(X_train,Y_train, 150)\n",
    "\n",
    "rf_model.fit(X_train, Y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "acc = accuracy_score(rf_predictions,Y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
